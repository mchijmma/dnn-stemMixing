{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# import hypertools as hyp\n",
    "# import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pylab import plot, show, figure, imshow\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import h5py\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler, scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from essentia.standard import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kLabels = ['b','g','v','k']\n",
    "kSR = 44100\n",
    "kN = 2048\n",
    "kHopLength = 1024\n",
    "kSeed = 7\n",
    "kType = 'mono'\n",
    "np.random.seed(kSeed)\n",
    "\n",
    "kPathFiles = './DAE-WIMP/' \n",
    "kPathAudio = './Music/Data/MedleyDB/Audio/info.tracks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadPickle(name, path = kPathFiles):  \n",
    "    \n",
    "    # load data from pkl file\n",
    "    with open(path + name, \"rb\") as fp:\n",
    "        loaded_data1 = pickle.load(fp)\n",
    "    print('%s loaded, %s ' % (name, type(loaded_data1)))\n",
    "    return loaded_data1\n",
    "\n",
    "def dumpPickle(d, name, path = kPathFiles):\n",
    "    \n",
    "    with open(path + name, 'wb') as output:\n",
    "    # Pickle dictionary using protocol 0.\n",
    "        pickle.dump(d, output)\n",
    "    print('%s Saved' % (name))\n",
    "    \n",
    "def loadH5(name, path = kPathFiles):  \n",
    "    \n",
    "    # load data from pkl file\n",
    "    with h5py.File(path + name,'r') as h5f:\n",
    "        b = h5f[name.split('.')[0]][:]\n",
    "#     h5f.close()\n",
    "    \n",
    "    print('%s loaded, %s ' % (name, type(b)))\n",
    "    \n",
    "    return b\n",
    "\n",
    "def saveH5(d, name, path = kPathFiles):\n",
    "    with h5py.File(path + name, 'w') as h5f:\n",
    "        h5f.create_dataset(name.split('.')[0], data = d)\n",
    "#     h5f.close() \n",
    "    print('%s Saved' % (name))\n",
    "\n",
    "\n",
    "def saveDataset(dataset, name):\n",
    "    for i in range(len(dataset)-2):\n",
    "        for j in kLabels:\n",
    "            saveH5(dataset[i+2][j], name+'_'+str(i)+'_'+j+'.h5')\n",
    "            \n",
    "def loadDataset(name):\n",
    "#     data = []\n",
    "    rawMagnitude = OrderedDict()\n",
    "    stemMagnitude = OrderedDict()\n",
    "    rawPhase = OrderedDict()\n",
    "    stemPhase = OrderedDict()\n",
    "    for i in range(4):\n",
    "        for j in kLabels:\n",
    "            if i == 0:\n",
    "                rawMagnitude[j] = (loadH5(name+'_'+str(i)+'_'+j+'.h5'))\n",
    "            elif i == 1:\n",
    "                stemMagnitude[j] = (loadH5(name+'_'+str(i)+'_'+j+'.h5'))\n",
    "            elif i == 2:\n",
    "                rawPhase[j] = (loadH5(name+'_'+str(i)+'_'+j+'.h5'))\n",
    "            elif i == 3:\n",
    "                stemPhase[j] = (loadH5(name+'_'+str(i)+'_'+j+'.h5'))\n",
    "    \n",
    "    return rawMagnitude, stemMagnitude, rawPhase, stemPhase\n",
    "\n",
    "# returns list with name of tracks that contain gInstrument\n",
    "# needs essentia to work (YAMLINPUT)\n",
    "# def getInfoTracks(group, type = 'All'):\n",
    "  \n",
    "#     semitones = np.concatenate((np.linspace(-4,-0.5,8),np.linspace(0.5,4,8)))\n",
    "  \n",
    "#     nameTracks = OrderedDict()\n",
    "#     raw_path = OrderedDict()\n",
    "#     stem_path = OrderedDict()\n",
    "#     stem_stereo_path = OrderedDict()\n",
    "#     entries = gInfoTracks.descriptorNames()\n",
    "    \n",
    "#     for instrument in group:\n",
    "#         name_tracks = []\n",
    "#         for entry in entries:\n",
    "#             split = entry.split('.')\n",
    "#             if instrument == split[2]:\n",
    "#                 name_tracks.append(split[1])\n",
    "              \n",
    "#         name_tracks = list(set(name_tracks))\n",
    "#         nameTracks[instrument] = name_tracks\n",
    "        \n",
    "#         if type == 'original':\n",
    "            \n",
    "#             for name in name_tracks:\n",
    "#                 raw_path[name+'_'+instrument] = gInfoTracks['track.%s.%s.raw_path' % (name, instrument)]\n",
    "#                 stem_path[name+'_'+instrument] = gInfoTracks['track.%s.%s.stem_path_mono' % (name, instrument)]      \n",
    "#                 stem_stereo_path[name+'_'+instrument] = gInfoTracks['track.%s.%s.stem_path_stereo' % (name, instrument)]\n",
    "    \n",
    "#         else:\n",
    "    \n",
    "#             for name in name_tracks:           \n",
    "    \n",
    "#                 raw_path[name] = gInfoTracks['track.%s.%s.raw_path' % (name, instrument)]\n",
    "#                 stem_path[name] = gInfoTracks['track.%s.%s.stem_path_mono' % (name, instrument)]      \n",
    "#                 stem_stereo_path[name] = gInfoTracks['track.%s.%s.stem_path_stereo' % (name, instrument)]\n",
    "    \n",
    "#                 for st in semitones:\n",
    "    \n",
    "#                     rname = raw_path[name]\n",
    "#                     sname = stem_path[name]\n",
    "#                     ssname = stem_stereo_path[name]\n",
    "    \n",
    "#                     name2 = name + '%+d' % (int(100*st))\n",
    "#                     #raw\n",
    "#                     name3 = rname.split('/')[-1].split('_')\n",
    "#                     name3[1] = name3[1] + '%+d' % (int(100*st))\n",
    "#                     name3 = '_'.join(name3)\n",
    "#                     name4 = rname.split('/')\n",
    "#                     name4[-1] = name3\n",
    "#                     name3 = '/'.join(name4)\n",
    "#                     raw_path[name2] = name3\n",
    "    \n",
    "#                     #stem\n",
    "#                     name3 = sname.split('/')[-1].split('_')\n",
    "#                     name3[1] = name3[1] + '%+d' % (int(100*st))\n",
    "#                     name3 = '_'.join(name3)\n",
    "#                     name4 = sname.split('/')\n",
    "#                     name4[-1] = name3\n",
    "#                     name3 = '/'.join(name4)\n",
    "#                     stem_path[name2] = name3 \n",
    "    \n",
    "#                     #stem_stereo\n",
    "#                     name3 = sname.split('/')[-1].split('_')\n",
    "#                     name3[1] = name3[1] + '%+d' % (int(100*st))\n",
    "#                     name3 = '_'.join(name3)\n",
    "#                     name4 = ssname.split('/')\n",
    "#                     name4[-1] = name3\n",
    "#                     name3 = '/'.join(name4)\n",
    "#                     stem_stereo_path[name2] = name3\n",
    "\n",
    "\n",
    "\n",
    "#     return nameTracks, raw_path, stem_path, stem_stereo_path \n",
    "\n",
    "\n",
    "# def getPathGroups():\n",
    "\n",
    "#     raw_Path = OrderedDict()\n",
    "#     stem_Path = OrderedDict()\n",
    "#     stemStereo_Path = OrderedDict()\n",
    "    \n",
    "#     kInstrument = ['electric bass']\n",
    "#     nameTracks, rawPath, stemPath, stemStereoPath = getInfoTracks(kInstrument, type = 'original')\n",
    "#     raw_Path['b'] = rawPath.values()\n",
    "#     stem_Path['b'] = stemPath.values()\n",
    "#     stemStereo_Path['b'] = stemStereoPath.values()\n",
    "    \n",
    "#     kInstrument = ['clean electric guitar',\n",
    "#                    'acoustic guitar',\n",
    "#                    'distorted electric guitar',\n",
    "#                    'banjo']\n",
    "#     nameTracks, rawPath, stemPath, stemStereoPath = getInfoTracks(kInstrument,type = 'original')\n",
    "#     raw_Path['g'] = rawPath.values()\n",
    "#     stem_Path['g'] = stemPath.values()\n",
    "#     stemStereo_Path['g'] = stemStereoPath.values()\n",
    "    \n",
    "#     kInstrument = ['male singer',\n",
    "#                    'female singer',\n",
    "#                    'male rapper']\n",
    "#     nameTracks, rawPath, stemPath, stemStereoPath = getInfoTracks(kInstrument,type = 'original')\n",
    "#     raw_Path['v'] = rawPath.values()\n",
    "#     stem_Path['v'] = stemPath.values()\n",
    "#     stemStereo_Path['v'] = stemStereoPath.values()\n",
    "    \n",
    "#     kInstrument = ['piano',\n",
    "#                    'synthesizer',\n",
    "#                    'tack piano',\n",
    "#                    'electric piano']\n",
    "#     nameTracks, rawPath, stemPath, stemStereoPath = getInfoTracks(kInstrument,type = 'original')\n",
    "#     raw_Path['k'] = rawPath.values()\n",
    "#     stem_Path['k'] = stemPath.values()\n",
    "#     stemStereo_Path['k'] = stemStereoPath.values()\n",
    "    \n",
    "#     return raw_Path, stem_Path, stemStereo_Path\n",
    "\n",
    "\n",
    "# def getTrainTestPaths():\n",
    "    \n",
    "#     semitones = np.concatenate((np.linspace(-4,-0.5,8),np.linspace(0.5,4,8)))\n",
    "    \n",
    "#     X_train = OrderedDict()\n",
    "#     X_train_aug = OrderedDict()\n",
    "#     X_test = OrderedDict()\n",
    "#     y_train = OrderedDict()\n",
    "#     y_train_aug = OrderedDict()\n",
    "#     y_test = OrderedDict()\n",
    "    \n",
    "#     for i in kLabels:\n",
    "        \n",
    "#         X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(gRawPath[i],\n",
    "#                                                             gStemPath[i],\n",
    "#                                                             train_size=0.9,\n",
    "#                                                             random_state=kSeed)\n",
    "    \n",
    "    \n",
    "#     for k in kLabels:\n",
    "        \n",
    "#         name_raw_aug = []\n",
    "#         name_stem_aug = []\n",
    "        \n",
    "#         #Raw\n",
    "#         for p in X_train[k]:\n",
    "#             name_raw_aug.append(p)\n",
    "#             for st in semitones:\n",
    "            \n",
    "#                 rname = p\n",
    "#                 name = '_'.join([p.split('/')[-1].split('_')[0], p.split('/')[-1].split('_')[1]])\n",
    "                \n",
    "                \n",
    "#                 name2 = name + '%+d' % (int(100*st))\n",
    "#                 #raw\n",
    "#                 name3 = rname.split('/')[-1].split('_')\n",
    "#                 name3[1] = name3[1] + '%+d' % (int(100*st))\n",
    "#                 name3 = '_'.join(name3)\n",
    "#                 name4 = rname.split('/')\n",
    "#                 name4[-1] = name3\n",
    "#                 name3 = '/'.join(name4)\n",
    "                \n",
    "#                 name_raw_aug.append(name3)\n",
    "                \n",
    "#         X_train_aug[k] = name_raw_aug\n",
    "        \n",
    "#         #Stem\n",
    "#         for p in y_train[k]:\n",
    "#             name_stem_aug.append(p)\n",
    "#             for st in semitones:\n",
    "            \n",
    "#                 rname = p\n",
    "#                 name = '_'.join([p.split('/')[-1].split('_')[0], p.split('/')[-1].split('_')[1]])\n",
    "                \n",
    "                \n",
    "#                 name2 = name + '%+d' % (int(100*st))\n",
    "#                 #raw\n",
    "#                 name3 = rname.split('/')[-1].split('_')\n",
    "#                 name3[1] = name3[1] + '%+d' % (int(100*st))\n",
    "#                 name3 = '_'.join(name3)\n",
    "#                 name4 = rname.split('/')\n",
    "#                 name4[-1] = name3\n",
    "#                 name3 = '/'.join(name4)\n",
    "                \n",
    "#                 name_stem_aug.append(name3)\n",
    "                \n",
    "#         y_train_aug[k] = name_stem_aug\n",
    "        \n",
    "#     return X_train, X_train_aug, X_test, y_train, y_train_aug, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gXtrain, gXtrainAug, gXtest, gYtrain, gYtrainAug, gYtest = getTrainTestPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gRawPath.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gStemPath.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gStemStereoPath.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gXtrain.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gXtrainAug.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gXtest.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gYtrainAug.pkl loaded, <class 'collections.OrderedDict'> \n",
      "gYtest.pkl loaded, <class 'collections.OrderedDict'> \n",
      "grid-b.pkl loaded, <type 'dict'> \n",
      "grid-g.pkl loaded, <type 'dict'> \n",
      "grid-v.pkl loaded, <type 'dict'> \n",
      "grid-k.pkl loaded, <type 'dict'> \n",
      "Train_0_b.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_0_g.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_0_v.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_0_k.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_1_b.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_1_g.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_1_v.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_1_k.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_2_b.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_2_g.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_2_v.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_2_k.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_3_b.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_3_g.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_3_v.h5 loaded, <type 'numpy.ndarray'> \n",
      "Train_3_k.h5 loaded, <type 'numpy.ndarray'> \n",
      "\n",
      "Executed in: 0:08:31.577348 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "# if os.path.isfile(kPathAudio):        \n",
    "#     yamlInput = YamlInput(filename=kPathAudio)\n",
    "#     gInfoTracks = yamlInput()\n",
    "# else:\n",
    "#     print(\"Yaml file not found\")\n",
    "    \n",
    "# gRawPath, gStemPath, gStemStereoPath = getPathGroups()\n",
    "# gXtrain, gXtrainAug, gXtest, gYtrain, gYtrainAug, gYtest = getTrainTestPaths()\n",
    "\n",
    "\n",
    "# #%%\n",
    "# dumpPickle(gRawPath, 'gRawPath.pkl', path = kPathFiles)\n",
    "# dumpPickle(gStemPath, 'gStemPath.pkl', path = kPathFiles)\n",
    "# dumpPickle(gStemStereoPath, 'gStemStereoPath.pkl', path = kPathFiles)\n",
    "# dumpPickle(gXtrain, 'gXtrain.pkl', path = kPathFiles)\n",
    "# dumpPickle(gYtrain, 'gYtrain.pkl', path = kPathFiles)\n",
    "# dumpPickle(gXtrainAug, 'gXtrainAug.pkl', path = kPathFiles)\n",
    "# dumpPickle(gXtest, 'gXtest.pkl', path = kPathFiles)\n",
    "# dumpPickle(gYtrainAug, 'gYtrainAug.pkl', path = kPathFiles)\n",
    "# dumpPickle(gYtest, 'gYtest.pkl', path = kPathFiles)\n",
    "\n",
    "gRawPath = loadPickle('gRawPath.pkl', path = kPathFiles)\n",
    "gStemPath = loadPickle('gStemPath.pkl', path = kPathFiles)\n",
    "gStemStereoPath = loadPickle('gStemStereoPath.pkl', path = kPathFiles)\n",
    "gXtrain = loadPickle('gXtrain.pkl', path = kPathFiles)\n",
    "# gYtrain = loadPickle('gYtrain.pkl', path = kPathFiles)\n",
    "gXtrainAug = loadPickle('gXtrainAug.pkl', path = kPathFiles)\n",
    "gXtest = loadPickle('gXtest.pkl', path = kPathFiles)\n",
    "gYtrainAug = loadPickle('gYtrainAug.pkl', path = kPathFiles)\n",
    "gYtest = loadPickle('gYtest.pkl', path = kPathFiles)\n",
    "\n",
    "gGridSearch = {}\n",
    "gGridSearch['b'] = loadPickle('grid-b.pkl', path = kPathFiles)\n",
    "gGridSearch['g'] = loadPickle('grid-g.pkl', path = kPathFiles)\n",
    "gGridSearch['v'] = loadPickle('grid-v.pkl', path = kPathFiles)\n",
    "gGridSearch['k'] = loadPickle('grid-k.pkl', path = kPathFiles)\n",
    "\n",
    "\n",
    "# saveDataset(DataTrain, 'Train')\n",
    "# saveDataset(DataTest, 'Test')\n",
    "\n",
    "DataTrain = loadDataset('Train')\n",
    "\n",
    "\n",
    "gXtrainMagnitude = DataTrain[0]\n",
    "gYtrainMagnitude = DataTrain[1]\n",
    "gXtrainPhase = DataTrain[2]\n",
    "gYtrainPhase = DataTrain[3]\n",
    "\n",
    "# DataTest = loadDataset('Test')\n",
    "\n",
    "\n",
    "# gXtestMagnitude = DataTest[0]\n",
    "# gYtestMagnitude = DataTest[1]\n",
    "# gXtestPhase = DataTest[2]\n",
    "# gYtestPhase = DataTest[3]\n",
    "\n",
    "# model_b = load_model(kPathFiles+'model_X-Y_b.h5')\n",
    "# model_g = load_model(kPathFiles+'model_X-Y_g.h5')\n",
    "# model_v = load_model(kPathFiles+'model_X-Y_v.h5')\n",
    "# model_k = load_model(kPathFiles+'model_X-Y_k.h5')\n",
    "\n",
    "\n",
    "print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths, sr = kSR, loudnessNorm = True):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        \n",
    "#         print(fp)\n",
    "        X,_sr = librosa.load(fp, sr=sr)\n",
    "\n",
    "        if loudnessNorm:\n",
    "            gain_lufs = (-23.0 - calculate_loudness(X, kSR))\n",
    "            gain = np.power(10, gain_lufs/20)\n",
    "            X = gain * X\n",
    "            \n",
    "        if X.shape[0] < 441000:\n",
    "                \n",
    "            X_ = np.zeros(441000)\n",
    "            X_[:X.shape[0]] = X\n",
    "            X = X_\n",
    "            \n",
    "        raw_sounds.append(X)\n",
    "        \n",
    "    return raw_sounds\n",
    "\n",
    "def spectogram(audio_files, sound_clip, sr=kSR, n_fft=kN,\n",
    "               hop_length=kHopLength):\n",
    "    spectograms = []\n",
    "    phase = []\n",
    "\n",
    "    audio_files = get_name(audio_files)\n",
    "             \n",
    "    for f in range(len(audio_files)):\n",
    "\n",
    "        D = librosa.stft(sound_clip[f], n_fft=n_fft, hop_length=hop_length)\n",
    "        spectograms.append(np.abs(D))\n",
    "        phase.append(np.angle(D))\n",
    "\n",
    "    return np.asarray(spectograms), np.asarray(phase)\n",
    "  \n",
    "\n",
    "\n",
    "def get_name(audio_files):\n",
    "    name = []\n",
    "    for i in range(len(audio_files)):\n",
    "        n = str(audio_files[i]).split('/')[len(str(audio_files[i]).split('/'))-1].split('.wav')[0]\n",
    "        name.append(n)\n",
    "    return name\n",
    "\n",
    "\n",
    "\n",
    "# Plots stem and raw track given a name.\n",
    "def plotStemRawTrack(t1, t2):\n",
    "  \n",
    "    plt.close()\n",
    "    ax = plt.subplot(111)\n",
    "    plt.rcParams['figure.figsize'] = (9,5)\n",
    "    Time1=np.linspace(0, len(t1)/kSR, num=len(t1))\n",
    "    \n",
    "    \n",
    "    lines1, = ax.plot(Time1, t2,'k', label='stem', alpha=1)\n",
    "    lines2, = ax.plot(Time1, t1, 'c', label='raw',alpha=0.5)\n",
    "    \n",
    "    #Sets legend outside plot\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "    ax.legend(handles=[lines1, lines2],loc='center', bbox_to_anchor=(0.8, -0.1),\n",
    "          fancybox=True, shadow=True, ncol=2)\n",
    "\n",
    "    plt.xlabel('time (s)')\n",
    "    plt.ylabel('amplitude')     \n",
    "    \n",
    "# Plot spectrum\n",
    "def plotStemRawSpectrum(rD, sD, type = 'spectrum', hop_size = kHopLength,\n",
    "                        power = True, yaxis = 'log', cmap = 'summer',\n",
    "                        colorbar = False):\n",
    "    plt.close()\n",
    "    \n",
    "#     rD = gRawMagnitude[idx]\n",
    "#     sD = gStemMagnitude[idx]\n",
    "    \n",
    "    if 'spectrum' in type:\n",
    "        rD = librosa.logamplitude(np.abs(rD)**2, ref_power=np.nanmax)\n",
    "        sD = librosa.logamplitude(np.abs(sD)**2, ref_power=np.nanmax)\n",
    "  \n",
    "    if power:\n",
    "        rD = rD**2\n",
    "        sD = sD**2\n",
    "  \n",
    "    plt.rcParams['figure.figsize'] = (9,10) \n",
    "#     plt.subplots_adjust(hspace=1.5)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.set_title('Raw')\n",
    "    librosa.display.specshow(rD,\n",
    "                             cmap=cmap, sr = kSR, hop_length = hop_size,\n",
    "                             y_axis=yaxis, x_axis='time')\n",
    "                            \n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "        lim = np.nanmax(np.abs(rD))\n",
    "        plt.clim(0,lim)\n",
    "    \n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.set_title('Stem')\n",
    "    librosa.display.specshow(sD,\n",
    "                             cmap=cmap, sr = kSR, hop_length = hop_size,\n",
    "                             y_axis=yaxis, x_axis='time')\n",
    "    if colorbar:\n",
    "        lim = np.nanmax(np.abs(rD))\n",
    "        plt.clim(0,lim)\n",
    "        plt.colorbar()\n",
    "        \n",
    "        \n",
    "#METHODS FOR LOUDNESS NORMALISATION\n",
    "\n",
    "def calculate_loudness(signal,fs):\n",
    "    # filter\n",
    "    if len(signal.shape)==1: # if shape (N,), then make (N,1)\n",
    "        signal_filtered = copy.copy(signal.reshape((signal.shape[0],1)))\n",
    "    else:\n",
    "        signal_filtered = copy.copy(signal)\n",
    "        \n",
    "    for i in range(signal_filtered.shape[1]):\n",
    "        signal_filtered[:,i] = K_filter(signal_filtered[:,i], fs)\n",
    "\n",
    "    # mean square\n",
    "    G = [1.0, 1.0, 1.0, 1.41, 1.41]\n",
    "    T_g = 0.400 # 400 ms gating block\n",
    "    Gamma_a = -70.0 # absolute threshold: -70 LKFS\n",
    "    overlap = .75 # relative overlap (0.0-1.0)\n",
    "    step = 1 - overlap\n",
    "\n",
    "    T = signal_filtered.shape[0]/fs # length of measurement interval in seconds\n",
    "    j_range = np.arange(0,(T-T_g)/(T_g*step))\n",
    "    z = np.ndarray(shape=(signal_filtered.shape[1],len(j_range))) # ?\n",
    "    # write in explicit for-loops for readability and translatability\n",
    "    for i in range(signal_filtered.shape[1]): # for each channel i\n",
    "        for j in j_range.astype(int): # for each window j\n",
    "            lbound = np.round(fs*T_g*j*step).astype(int)\n",
    "            hbound = np.round(fs*T_g*(j*step+1)).astype(int)\n",
    "            z[i,j] = (1/(T_g*fs))*np.sum(np.square(signal_filtered[lbound:hbound, i]))\n",
    "\n",
    "    G_current = np.array(G[:signal_filtered.shape[1]]) # discard weighting coefficients G_i unused channels\n",
    "    n_channels = G_current.shape[0]\n",
    "    l = [-.691 + 10.0*np.log10(np.sum([G_current[i]*z[i,j.astype(int)] for i in range(n_channels)])) \\\n",
    "             for j in j_range]\n",
    "    #print 'l: '+str(l)\n",
    "\n",
    "    # throw out anything below absolute threshold:\n",
    "    indices_gated = [idx for idx,el in enumerate(l) if el > Gamma_a] \n",
    "    z_avg = [np.mean([z[i,j] for j in indices_gated]) for i in range(n_channels)]\n",
    "    Gamma_r = -.691 + 10.0*np.log10(np.sum([G_current[i]*z_avg[i] for i in range(n_channels)])) - 10.0\n",
    "    # throw out anything below relative threshold:\n",
    "    indices_gated = [idx for idx,el in enumerate(l) if el > Gamma_r] \n",
    "    z_avg = [np.mean([z[i,j] for j in indices_gated]) for i in range(n_channels)]\n",
    "    L_KG = -.691 + 10.0*np.log10(np.sum([G_current[i]*z_avg[i] for i in range(n_channels)]))\n",
    "\n",
    "    return L_KG\n",
    "\n",
    "def K_filter(signal, fs, debug=False):\n",
    "    # apply K filtering as specified in EBU R-128 / ITU BS.1770-4\n",
    "       \n",
    "    # pre-filter 1\n",
    "    f0 = 1681.9744509555319\n",
    "    G  = 3.99984385397\n",
    "    Q  = 0.7071752369554193\n",
    "    K  = np.tan(np.pi * f0 / fs) # TODO: precompute\n",
    "    Vh = np.power(10.0, G / 20.0)\n",
    "    Vb = np.power(Vh, 0.499666774155)\n",
    "    a0_ = 1.0 + K / Q + K * K\n",
    "    b0 = (Vh + Vb * K / Q + K * K) / a0_\n",
    "    b1 = 2.0 * (K * K -  Vh) / a0_\n",
    "    b2 = (Vh - Vb * K / Q + K * K) / a0_\n",
    "    a0 = 1.0\n",
    "    a1 = 2.0 * (K * K - 1.0) / a0_\n",
    "    a2 = (1.0 - K / Q + K * K) / a0_\n",
    "    signal_1 = lfilter([b0,b1,b2],[a0,a1,a2],signal)\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure(figsize=(9,9))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        w, h1 = freqz([b0,b1,b2], [a0,a1,a2], worN=8000)#np.logspace(-4, 3, 2000))\n",
    "        plt.semilogx((fs * 0.5 / np.pi) * w, 20*np.log10(abs(h1)))\n",
    "        plt.title('Pre-filter 1')\n",
    "        plt.xlabel('Frequency [Hz]')\n",
    "        plt.ylabel('Gain [dB]')\n",
    "        plt.xlim([20, 20000])\n",
    "        plt.ylim([-10,10])\n",
    "        plt.grid(True, which='both')\n",
    "        ax = plt.axes()\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "        plt.show()\n",
    "    \n",
    "    # pre-filter 2\n",
    "    f0 = 38.13547087613982\n",
    "    Q  =  0.5003270373253953\n",
    "    K  = np.tan(np.pi * f0 / fs)\n",
    "    a0 = 1.0\n",
    "    a1 = 2.0 * (K * K - 1.0) / (1.0 + K / Q + K * K)\n",
    "    a2 = (1.0 - K / Q + K * K) / (1.0 + K / Q + K * K)\n",
    "    b0 = 1.0\n",
    "    b1 = -2.0\n",
    "    b2 = 1.0\n",
    "    signal_2 = lfilter([b0,b1,b2],[a0,a1,a2],signal_1)\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure(figsize=(9,9))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        w, h2 = freqz([b0,b1,b2], [a0,a1,a2], worN=8000)#np.logspace(-4, 3, 2000))\n",
    "        plt.semilogx((fs * 0.5 / np.pi) * w, 20*np.log10(abs(h2)))\n",
    "        plt.title('Pre-filter 2')\n",
    "        plt.xlabel('Frequency [Hz]')\n",
    "        plt.ylabel('Gain [dB]')\n",
    "        plt.xlim([10, 20000])\n",
    "        plt.ylim([-30,5])\n",
    "        plt.grid(True, which='both')\n",
    "        ax = plt.axes()\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "        plt.show()\n",
    "    \n",
    "    return signal_2 # return signal passed through 2 pre-filters        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAudioMagnitudePhase(rawPath, stemPath, loudnessNorm = True):\n",
    "    \n",
    "    rawAudio = OrderedDict()\n",
    "    stemAudio = OrderedDict()\n",
    "    rawMagnitude = OrderedDict()\n",
    "    stemMagnitude = OrderedDict()\n",
    "    rawPhase = OrderedDict()\n",
    "    stemPhase = OrderedDict()\n",
    "    \n",
    "    for k in kLabels:\n",
    "        \n",
    "        \n",
    "\n",
    "        rawPath['b'] = [ x for x in rawPath['b'] if 'EthanHein_BluesForNofi' not in x ]\n",
    "        stemPath['b'] = [ x for x in stemPath['b'] if 'EthanHein_BluesForNofi' not in x ]\n",
    "#         rawPath['b'] = [ x for x in rawPath['b'] if 'Lushlife_ToynbeeSuite2' not in x ]\n",
    "#         stemPath['b'] = [ x for x in stemPath['b'] if 'Lushlife_ToynbeeSuite2' not in x ]\n",
    "#         rawPath['b'] = [ x for x in rawPath['b'] if 'EthanHein_HarmonicaFigure' not in x ]\n",
    "#         stemPath['b'] = [ x for x in stemPath['b'] if 'EthanHein_HarmonicaFigure' not in x ]\n",
    "        rawPath['g'] = [ x for x in rawPath['g'] if 'EthanHein_GirlOnABridge' not in x ]\n",
    "        stemPath['g'] = [ x for x in stemPath['g'] if 'EthanHein_GirlOnABridge' not in x ]\n",
    "        rawPath['g'] = [ x for x in rawPath['g'] if 'BigTroubles_Phantom' not in x ]\n",
    "        stemPath['g'] = [ x for x in stemPath['g'] if 'BigTroubles_Phantom' not in x ]\n",
    "        rawPath['v'] = [ x for x in rawPath['v'] if 'Wolf_DieBekherte' not in x ]\n",
    "        stemPath['v'] = [ x for x in stemPath['v'] if 'Wolf_DieBekherte' not in x ]\n",
    "        rawPath['v'] = [ x for x in rawPath['v'] if 'MatthewEntwistle_Lontano' not in x ]\n",
    "        stemPath['v'] = [ x for x in stemPath['v'] if 'MatthewEntwistle_Lontano' not in x ]\n",
    "        rawPath['k'] = [ x for x in rawPath['k'] if 'JoelHelander_Definition' not in x ]\n",
    "        stemPath['k'] = [ x for x in stemPath['k'] if 'JoelHelander_Definition' not in x ]\n",
    "\n",
    "        print('Loading {} raw audio files \\n'.format(k))\n",
    "        rawAudio[k] = load_sound_files(rawPath[k], loudnessNorm=loudnessNorm)\n",
    "        \n",
    "        print('Loading {} stem audio files \\n'.format(k))\n",
    "        stemAudio[k] = load_sound_files(stemPath[k], loudnessNorm=loudnessNorm)\n",
    "\n",
    "        print('Obtaining {} raw magnitude and phase \\n'.format(k))\n",
    "        rawMagnitude[k], rawPhase[k] = spectogram(rawPath[k], rawAudio[k])\n",
    "        \n",
    "        print('Obtaining {} stem magnitude and phase \\n'.format(k))\n",
    "        stemMagnitude[k], stemPhase[k] = spectogram(stemPath[k], stemAudio[k]) \n",
    "        \n",
    "    return rawAudio, stemAudio, rawMagnitude, stemMagnitude, rawPhase, stemPhase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading b raw audio files \n",
      "\n",
      "Loading b stem audio files \n",
      "\n",
      "Obtaining b raw magnitude and phase \n",
      "\n",
      "Obtaining b stem magnitude and phase \n",
      "\n",
      "Loading g raw audio files \n",
      "\n",
      "Loading g stem audio files \n",
      "\n",
      "Obtaining g raw magnitude and phase \n",
      "\n",
      "Obtaining g stem magnitude and phase \n",
      "\n",
      "Loading v raw audio files \n",
      "\n",
      "Loading v stem audio files \n",
      "\n",
      "Obtaining v raw magnitude and phase \n",
      "\n",
      "Obtaining v stem magnitude and phase \n",
      "\n",
      "Loading k raw audio files \n",
      "\n",
      "Loading k stem audio files \n",
      "\n",
      "Obtaining k raw magnitude and phase \n",
      "\n",
      "Obtaining k stem magnitude and phase \n",
      "\n",
      "\n",
      "Executed in: 0:00:09.453692 \n",
      " 7 Bass r/s tracks \n",
      " 8 Guitar r/s tracks \n",
      " 7 Keys r/s tracks \n",
      " 6 Vocal r/s tracks \n",
      "\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "DataTest = getAudioMagnitudePhase(gXtest, gYtest)\n",
    "\n",
    "gXtestAudio = DataTest[0]\n",
    "gYtestAudio = DataTest[1]\n",
    "gXtestMagnitude = DataTest[2]\n",
    "gYtestMagnitude = DataTest[3]\n",
    "gXtestPhase = DataTest[4]\n",
    "gYtestPhase = DataTest[5]\n",
    "\n",
    "print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)),\n",
    "     '{} Bass r/s tracks \\n'.format(gXtestPhase['b'].shape[0]),\n",
    "     '{} Guitar r/s tracks \\n'.format(gXtestPhase['g'].shape[0]),\n",
    "     '{} Keys r/s tracks \\n'.format(gXtestPhase['k'].shape[0]),\n",
    "     '{} Vocal r/s tracks \\n'.format(gXtestPhase['v'].shape[0])) \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "DataTrain = getAudioMagnitudePhase(gXtrainAug, gYtrainAug)\n",
    "\n",
    "gXtrainAudio = DataTrain[0]\n",
    "gYtrainAudio = DataTrain[1]\n",
    "gXtrainMagnitude = DataTrain[2]\n",
    "gYtrainMagnitude = DataTrain[3]\n",
    "gXtrainPhase = DataTrain[4]\n",
    "gYtrainPhase = DataTrain[5]\n",
    "\n",
    "print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)),\n",
    "     '{} Bass r/s tracks \\n'.format(gYtrainPhase['b'].shape[0]),\n",
    "     '{} Guitar r/s tracks \\n'.format(gYtrainPhase['g'].shape[0]),\n",
    "     '{} Keys r/s tracks \\n'.format(gYtrainPhase['k'].shape[0]),\n",
    "     '{} Vocal r/s tracks \\n'.format(gYtrainPhase['v'].shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "Data = getAudioMagnitudePhase(gRawPath, gStemPath)\n",
    "\n",
    "gXAudio = Data[0]\n",
    "gYAudio = Data[1]\n",
    "gXMagnitude = Data[2]\n",
    "gYMagnitude = Data[3]\n",
    "gXPhase = Data[4]\n",
    "gYPhase = Data[5]\n",
    "\n",
    "print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)),\n",
    "     '{} Bass r/s tracks \\n'.format(gYPhase['b'].shape[0]),\n",
    "     '{} Guitar r/s tracks \\n'.format(gYPhase['g'].shape[0]),\n",
    "     '{} Keys r/s tracks \\n'.format(gYPhase['k'].shape[0]),\n",
    "     '{} Vocal r/s tracks \\n'.format(gYPhase['v'].shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 'b'\n",
    "i = 0\n",
    "\n",
    "plotStemRawSpectrum(gXtestMagnitude[k][i], gYtestMagnitude[k][i], colorbar = False, power = False)\n",
    "i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 'v'\n",
    "i = 0\n",
    "\n",
    "plotStemRawTrack(gXtestAudio[k][i], gYtestAudio[k][i])\n",
    "i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gridsearch Nerual net.\n",
    "gridResult = {}\n",
    "\n",
    "\n",
    "for k in kLabels:\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    label = k\n",
    "    X = gXMagnitude[k].reshape(-1,gXMagnitude[k].shape[1])\n",
    "    Y = gYMagnitude[k].reshape(-1,gYMagnitude[k].shape[1])\n",
    "\n",
    "\n",
    "    batch_size = [10, 20, 40, 50, 60, 70]\n",
    "    epochs = [50, 100, 150, 200]\n",
    "    init_mode = ['zero','uniform','lecun_uniform', 'normal']\n",
    "    activation = ['selu','relu','elu','tanh','sigmoid']\n",
    "    weight_constraint = [1, 2, 3, 4, 5]\n",
    "    dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "    neurons = [64, 128, 256]\n",
    "\n",
    "\n",
    "    est = KerasRegressor(build_fn=DAE, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    param_grid = dict(neurons=neurons, epochs=epochs)\n",
    "\n",
    "\n",
    "\n",
    "    grid = GridSearchCV(estimator=est, param_grid=param_grid, n_jobs=1, verbose=1)\n",
    "    grid_result = grid.fit(X, X)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n label - %s - Best: %f using %s\" % (label, grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "    gridResult[label] = (\"\\n label - %s - Best: %f using %s\" % (label, grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "    dumpPickle(gridResult, 'grid-'+label+'.pkl')\n",
    "\n",
    "    print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print results gridSearch\n",
    "\n",
    "for k in kLabels:\n",
    "    label = k\n",
    "    print(gGridSearch[k][k])\n",
    "    means = gGridSearch[k][k+'mean']\n",
    "    stds = gGridSearch[k][k+'stds']\n",
    "    params = gGridSearch[k][k+'params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DAE(neurons=128, init_mode='lecun_normal', act_function='relu', dropout_rate=0.2, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1025, input_dim=1025, \n",
    "                    kernel_initializer=init_mode, \n",
    "                    activation=act_function,\n",
    "                    name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(neurons*4,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    activation=act_function,\n",
    "                    name='dense_2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     model.add(Dense(neurons*2, kernel_initializer=init_mode, activation=act_function))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     model.add(Dense(neurons*4, kernel_initializer=init_mode, activation=act_function))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1025,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    activation=act_function,\n",
    "                    name='dense_3'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def DAE_R(neurons=128, init_mode='lecun_normal', act_function='relu', dropout_rate=0.2, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1025, input_dim=1025, \n",
    "                    kernel_initializer=init_mode, \n",
    "                    activation=act_function,\n",
    "                    name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(neurons*4,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    activation=act_function,\n",
    "                    name='dense_2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     model.add(Dense(neurons*2, kernel_initializer=init_mode, activation=act_function))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     model.add(Dense(neurons*4, kernel_initializer=init_mode, activation=act_function))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1025,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    activation=act_function,\n",
    "                    name='dense_3'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1025,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    activation=act_function,\n",
    "                    name='dense_4'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gYtrainMagnitude['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gXtrainMagnitude['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = gXtrainMagnitude['b'] / gXtrainMagnitude['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = R * gXtrainMagnitude['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in 'b':\n",
    "\n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    R = gYtrainMagnitude[k] / gXtrainMagnitude[k]\n",
    "    X = gXtrainMagnitude[k].reshape(-1, gXtrainMagnitude[k].shape[1])\n",
    "    Y = gYtrainMagnitude[k].reshape(-1, gYtrainMagnitude[k].shape[1])\n",
    "    R = R.reshape(-1, R.shape[1])\n",
    "    \n",
    "    model = DAE(neurons = 256)\n",
    "    \n",
    "    model.fit(X, X, batch_size=431, epochs=1, validation_split=0.0, shuffle='batch')\n",
    "    nameModel = kPathFiles+'model_X-X_'+k+'.h5'\n",
    "    model.save(nameModel) \n",
    "    \n",
    "    model.fit(X, Y, batch_size=431, epochs=1, validation_split=0.0, shuffle='batch')\n",
    "    nameModel = kPathFiles+'model_X-Y_'+k+'.h5'\n",
    "    nameWeights = kPathFiles+'model_X-Y_weights_'+k+'.h5'\n",
    "    model.save(nameModel) \n",
    "    model.save_weights(nameWeights)\n",
    "    \n",
    "    model_R = DAE_R(neurons = 256)\n",
    "    model_R.load_weights(nameWeights, by_name=True)\n",
    "    \n",
    "    model_R.fit(X, R, batch_size=431, epochs=1, validation_split=0.0, shuffle='batch')\n",
    "    nameModel = kPathFiles+'model_X-R_'+k+'.h5'\n",
    "    model.save(nameModel) \n",
    "    \n",
    "    print('\\nExecuted in: {} \\n'.format(str(datetime.now() - startTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_spectogram(audio_files, spectogram, sr=kSR, win_length=kN,\n",
    "                       hop_length=kHopLength):\n",
    "    sound_clip = []\n",
    "    audio_files = get_name(audio_files)\n",
    "    i = 1\n",
    "#     fig = plt.figure(figsize=(10,20), dpi = 900)               \n",
    "    for f in range(len(audio_files)):\n",
    "        s = librosa.core.istft(spectogram[f], hop_length=hop_length,\n",
    "                               win_length=win_length)\n",
    "\n",
    "        sound_clip.append(s)\n",
    "#        plt.subplot(10,1,i)            \n",
    "#        librosa.display.waveplot(s, sr=sr, color=color)\n",
    "#        plt.title(audio_files[f].title())\n",
    "#        i += 1        \n",
    "#    plt.tight_layout()\n",
    "#    plt.suptitle('Waveform',x=0.5, y=1.008, fontsize=18)\n",
    "    return np.asarray(sound_clip)\n",
    "#plt.show()    \n",
    "\n",
    "def reconstruct_spectogram(magnitude, phase, hop_length=kHopLength):\n",
    "    D = []\n",
    "    for i in range(len(magnitude)):\n",
    "        _D = librosa.core.phase_vocoder(magnitude[i,:,:] * np.exp(1j*phase[i,:,:]),\n",
    "                                        1, hop_length=hop_length)\n",
    "        D.append(_D)\n",
    "    return np.asarray(D)\n",
    "\n",
    "def post_processing(path, name_files, audio, sr=kSR, color='b'):\n",
    "\n",
    "#     plot_waves(audio_files, audio, color=color)    \n",
    "#     magnitude, phase =  spectogram(audio_files, audio, color=color) \n",
    "    #rms = rms_level(audio_files, audio, magnitude, color=color)\n",
    "    #sc = spectral_centroid(audio_files, audio, magnitude, color=color) \n",
    "    \n",
    "    for i in range(len(name_files)):\n",
    "        name = name_files[i].split('/')[-1] \n",
    "        _path = path +name   \n",
    "        librosa.output.write_wav(_path, audio[i], sr=sr, norm=False)  \n",
    "        print('{} - saved !'.format(name))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, name_files, mag_input, phase_input, sr=kSR):\n",
    "    \n",
    "    _mag_input = mag_input.reshape(-1,mag_input.shape[1])\n",
    "    encode_decode = model.predict(_mag_input, batch_size=431)\n",
    "    magnitude = np.asarray(encode_decode)\n",
    "    magnitude = magnitude.reshape(-1,mag_input.shape[1],mag_input.shape[2])\n",
    "    spectogram = reconstruct_spectogram(magnitude, phase_input)\n",
    "#     plot_waves(name_files, audio_input)\n",
    "    audio_output = inverse_spectogram(name_files, spectogram)\n",
    "    \n",
    "    return audio_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio = test_model(model_b, gXtest['b'], gXtestMagnitude['b'], gXtestPhase['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvaLuna_Waterduct_STEM_01.wav - saved !\n",
      "TheScarletBrand_LesFleursDuMal_STEM_02.wav - saved !\n",
      "DreamersOfTheGhetto_HeavyLove_STEM_01.wav - saved !\n",
      "Auctioneer_OurFutureFaces_STEM_02.wav - saved !\n",
      "KarimDouaidy_Hopscotch_STEM_01.wav - saved !\n",
      "PortStWillow_StayEven_STEM_10.wav - saved !\n",
      "ClaraBerryAndWooldog_WaltzForMyVictims_STEM_02.wav - saved !\n",
      "AClassicEducation_NightOwl_STEM_04.wav - saved !\n",
      "Phoenix_SeanCaughlinsTheScartaglen_STEM_01.wav - saved !\n",
      "AimeeNorwich_Child_STEM_03.wav - saved !\n",
      "Phoenix_LarkOnTheStrandDrummondCastle_STEM_01.wav - saved !\n",
      "LizNelson_Rainfall_STEM_05.wav - saved !\n",
      "MusicDelta_Reggae_STEM_03.wav - saved !\n",
      "PortStWillow_StayEven_STEM_07.wav - saved !\n",
      "LizNelson_Coldwar_STEM_01.wav - saved !\n",
      "MusicDelta_Disco_STEM_04.wav - saved !\n",
      "TheDistricts_Vermont_STEM_05.wav - saved !\n",
      "Lushlife_ToynbeeSuite_STEM_26.wav - saved !\n",
      "BrandonWebster_YesSirICanFly_STEM_02.wav - saved !\n",
      "MusicDelta_Rock_STEM_05.wav - saved !\n",
      "FamilyBand_Again_STEM_09.wav - saved !\n",
      "MichaelKropf_AllGoodThings_STEM_01.wav - saved !\n",
      "StevenClark_Bounty_STEM_09.wav - saved !\n",
      "MusicDelta_FusionJazz_STEM_04.wav - saved !\n",
      "InvisibleFamiliars_DisturbingWildlife_STEM_10.wav - saved !\n",
      "MatthewEntwistle_FairerHopes_STEM_13.wav - saved !\n",
      "Snowmine_Curfews_STEM_09.wav - saved !\n",
      "ClaraBerryAndWooldog_Stella_STEM_06.wav - saved !\n"
     ]
    }
   ],
   "source": [
    "gZAudio = {}\n",
    "for k in kLabels:\n",
    "    \n",
    "    if k == 'b':\n",
    "        model = model_b\n",
    "    elif k == 'g':\n",
    "        model = model_g\n",
    "    elif k == 'v':\n",
    "        model = model_v\n",
    "    elif k == 'k':\n",
    "        model = model_k\n",
    "        \n",
    "#     post_processing('/homes/mamr3/dae/Music/Results/{}/X/'.format(k), gXtest[k], gXtestAudio[k])\n",
    "#     post_processing('/homes/mamr3/dae/Music/Results/{}/Y/'.format(k), gYtest[k], gYtestAudio[k])\n",
    "    \n",
    "    audio = test_model(model, gXtest[k], gXtestMagnitude[k], gXtestPhase[k])\n",
    "    gZAudio[k] = librosa.util.fix_length(audio, len(gXtestAudio[k][0]))\n",
    "    \n",
    "    for i in range(len(gZAudio[k])):\n",
    "        X = gZAudio[k][i] \n",
    "        gain_lufs = (-23.0 - calculate_loudness(X, kSR))\n",
    "        gain = np.power(10, gain_lufs/20)\n",
    "        gZAudio[k][i] = gain * X\n",
    "    \n",
    "    post_processing('/homes/mamr3/dae/Music/Results/{}/Z/'.format(k), gYtest[k], gZAudio[k])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots stem and raw track given a name.\n",
    "def plotResultsWave(t1, t2, label):\n",
    "  \n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (9,20)\n",
    "    \n",
    "    Time1=np.linspace(0, t1[label][0].shape[0]/kSR, num=t1[label][0].shape[0])\n",
    "    \n",
    "    for i in range(len(t1[label])):\n",
    "        \n",
    "        ax = plt.subplot(len(t1[label]),1,i+1)\n",
    "        \n",
    "        lines1, = ax.plot(Time1, t2[label][i],'k', label='stem', alpha=1)\n",
    "        lines2, = ax.plot(Time1, t1[label][i], 'c', label='dae',alpha=0.5)\n",
    "\n",
    "        #Sets legend outside plot\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "        ax.legend(handles=[lines1, lines2],loc='center', bbox_to_anchor=(0.8, -0.1),\n",
    "              fancybox=True, shadow=True, ncol=2)\n",
    "\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.ylabel('amplitude')     \n",
    "    \n",
    "# Plot spectrum\n",
    "def plotResultsSpectrum(D1, D2, label, type = 'spectrum', hop_size = kHopLength,\n",
    "                        power = True, yaxis = 'log', cmap = 'summer',\n",
    "                        colorbar = False):\n",
    "    plt.close()\n",
    "    \n",
    "#     rD = gRawMagnitude[idx]\n",
    "#     sD = gStemMagnitude[idx]\n",
    "\n",
    "    for i in range(len(D1[label])):\n",
    "    \n",
    "        if 'spectrum' in type:\n",
    "            rD = librosa.logamplitude(np.abs(D1[label][0])**2, ref_power=np.nanmax)\n",
    "            sD = librosa.logamplitude(np.abs(D2[label][0])**2, ref_power=np.nanmax)\n",
    "\n",
    "        if power:\n",
    "            rD = rD**2\n",
    "            sD = sD**2\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = (9,10) \n",
    "#     plt.subplots_adjust(hspace=1.5)\n",
    "        ax = plt.subplot(len(t1[label]),1,i+1)\n",
    "        ax1 = plt.subplot(len(D1[label]),1,i+2)\n",
    "        ax1.set_title('Raw')\n",
    "        librosa.display.specshow(rD,\n",
    "                                 cmap=cmap, sr = kSR, hop_length = hop_size,\n",
    "                                 y_axis=yaxis, x_axis='time')\n",
    "                            \n",
    "    #     if colorbar:\n",
    "    #         plt.colorbar()\n",
    "    #         lim = np.nanmax(np.abs(rD))\n",
    "    #         plt.clim(0,lim)\n",
    "    \n",
    "        ax2 = plt.subplot(2,1,2)\n",
    "        ax2.set_title('Stem')\n",
    "        librosa.display.specshow(sD,\n",
    "                                 cmap=cmap, sr = kSR, hop_length = hop_size,\n",
    "                                 y_axis=yaxis, x_axis='time')\n",
    "    #     if colorbar:\n",
    "    #         lim = np.nanmax(np.abs(rD))\n",
    "    #         plt.clim(0,lim)\n",
    "    #         plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotResultsWave(gZAudio, gYtestAudio, 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(gZAudio['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gZAudio['b'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
